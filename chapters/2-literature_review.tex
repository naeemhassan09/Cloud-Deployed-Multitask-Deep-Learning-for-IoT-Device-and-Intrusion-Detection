% --- chapters/literature_review.tex ---
\section{IoT Security Landscape}

The rapid proliferation of IoT devices—expected to exceed 75 billion by 2025—has transformed everyday environments into complex, interconnected cyber-physical systems \parencite{Laghari2024}. While this expansion accelerates digital transformation, it simultaneously introduces unprecedented security risks across consumer, industrial, and critical-infrastructure domains \parencite{Aldehim2025}. Device heterogeneity, weak firmware validation, and inconsistent encryption protocols have created fragmented ecosystems where standardised threat detection remains challenging \parencite{Nazir2025}.
Studies by \textcite{Erukala2025} and \textcite{Rohilla2024} highlight how design flaws in low-cost IoT components—such as unsecured communication channels and default credentials—enable large-scale botnet formation. These systemic vulnerabilities render traditional, rule-based intrusion detection obsolete in dynamic IoT topologies.

Existing reviews have established the need for scalable, adaptive intrusion-detection frameworks \parencite{Patil2025}. However, few works translate conceptual security taxonomies into deployable, resource-aware models. This research builds upon those foundations by proposing a multitask, deep-learning-based framework capable of concurrent device identification and intrusion detection—bridging the persistent gap between theoretical security design and operational deployment.

\clearpage
\section{Intrusion Detection in IoT Networks}

\subsection{Classical Machine Learning versus Deep Learning}

Traditional algorithms—Random Forest, SVM, and K-NN—performed adequately on small, linearly separable datasets but deteriorated in high-dimensional network-flow data \parencite{Nazir2025}. Recent works \parencite{Alsubaei2025, Amine2025} demonstrate that deep-learning architectures outperform these classical techniques in accuracy and recall for complex IoT traffic. Nevertheless, most are single-task systems requiring separate training for each security objective, leading to computational redundancy.
\\
Comparative evaluations \parencite{Mahdi2025} show that while hybrid DL models achieve strong precision, they often demand expensive GPUs and exhibit high inference latency. The proposed shared-encoder multitask approach in this study mitigates those issues by jointly optimising related representations, reducing training duplication while maintaining detection fidelity.

\subsection{CNN, RNN and Transformer-Based Methods}

Hybrid models combining convolutional and sequential layers have become dominant in IoT intrusion detection \parencite{Gueriani2024, Ullah2023}. CNN layers excel at extracting spatial correlations among packet features, whereas LSTM and GRU capture temporal dependencies in session sequences. 
\\
However, both architectures struggle with long-range dependencies and limited contextual reasoning.
Transformers, leveraging self-attention, overcome these issues by dynamically weighting global relationships within traffic flows \parencite{Kodadi2025}. They have demonstrated superior robustness to protocol noise and missing packets but remain under-explored for multitask adaptation.
\\
Recent comparative analyses \parencite{Tseng2024} confirm transformers’ dominance in accuracy (> 99 percent macro-F1) but note a scarcity of latency benchmarks and explainability evaluation. This research extends transformer applications through a CNN–Transformer hybrid encoder optimised for real-time inference and multitask learning.

\subsection{Hybrid and Two-Stage Models}

Hybrid and multi-stage deep learning architectures have emerged as one of the most effective approaches for intrusion detection in IoT networks, combining the strengths of spatial and temporal feature extraction mechanisms. These architectures often integrate Convolutional Neural Networks (CNNs) for feature learning with sequential models such as Long Short-Term Memory (LSTM) or Gated Recurrent Units (GRU) for capturing temporal dependencies in network traffic data. \textcite{Patil2025} demonstrated that CNN–LSTM hybrids achieved high detection accuracy across diverse attack categories by leveraging CNNs to extract packet-level features and LSTMs to interpret sequential dependencies. However, their model was designed primarily for offline training and did not evaluate inference latency or suitability for real-time, cloud-based deployment. This omission presents a critical limitation for IoT security systems that require rapid response within resource-constrained edge environments.

Similarly, \textcite{Hnamte2023} proposed a two-stage LSTM–autoencoder architecture that first learned normal behavioural representations of IoT devices and then identified deviations as anomalies. While this approach significantly improved sensitivity to subtle attack patterns and achieved strong results on benchmark datasets, it incurred heavy computational overhead due to long recurrent sequences and multiple training phases. The large memory footprint of the model and its lack of parallelisation limited its applicability in real-world IoT deployments where computational and energy resources are restricted.

Recent studies have attempted to overcome these issues by introducing ensemble and cascaded hybrid frameworks. \textcite{Mahdi2025} combined convolutional and dense layers in a multi-stage pipeline to capture hierarchical representations of IoT traffic, reporting improved robustness under adversarial noise. However, their framework required multiple independently trained components, resulting in redundant parameters and increased inference time. \textcite{Babar2025} further examined hybrid CNN–BiLSTM systems for healthcare IoT security, showing improved F1-scores but acknowledging difficulties in achieving containerised deployment and maintaining consistent latency across platforms.

In response to these challenges, the proposed CNN–Transformer encoder in this study replaces heavy recurrent layers with efficient attention-based modules that provide superior long-range dependency modelling without sequential bottlenecks. Transformers compute relationships across all positions in a flow sequence simultaneously, allowing for parallelisation and lower latency. This architectural design ensures inference below 100~ms per 1,000 network flows, making it suitable for real-time detection within containerised microservices deployed on cloud or edge environments.

Moreover, to improve representational efficiency, this work incorporates the multitask learning concept introduced by \textcite{Dinh2023}, who employed constrained twin variational autoencoders to jointly model related intrusion tasks. Their findings demonstrated that sharing latent representations across correlated objectives reduces redundancy and enhances generalisation. Building upon this principle, the proposed multitask CNN–Transformer encoder utilises a shared feature extractor with task-specific classification heads for device identification and intrusion detection. This not only minimises duplicated computation but also allows inter-task knowledge transfer, improving robustness to unseen traffic patterns and new device types.

The resulting architecture represents a synthesis of the advantages of hybrid and multitask paradigms—combining CNN-based spatial abstraction, transformer-based contextual reasoning, and multitask parameter sharing into a single, deployable framework. This balance between accuracy, interpretability, and computational efficiency directly addresses the operational constraints and research gaps identified in earlier hybrid intrusion-detection studies.

\section{Cloud-Native and Deployment Practices}

Recent work highlights the shift from experimental modelling to deployable microservice architectures. 
\textcite{Naayini2025} discussed containerised pipelines for scalable AI systems using Docker and Kubernetes, while \textcite{Caleanu2024} outlined web application deployment of healthcare models. 
While these studies address operationalisation, they do not cover intrusion detection. This project adapts their approaches to IoT cybersecurity by deploying the multitask CNN Transformer model as a FastAPI microservice on AWS ECS, with CI/CD automation and real-time monitoring using Prometheus and Grafana.
This ensures continuous observability and reproducibility, aligning deep-learning research with production-level reliability.

\section{Multitask and Federated Learning Methods}

Multitask Learning (MTL) and Federated Learning (FL) are important approaches for enhancing efficiency and scalability in modern IoT intrusion detection systems. Both address the drawbacks of isolated, single-task models, which require separate training for each classification objective and lead to redundant computation and high memory usage. MTL jointly optimises related tasks within a shared environment, while FL decentralises model training across edge nodes to preserve privacy and reduce communication overhead.
\\
MTL uses the interdependence of related tasks to improve generalisation and efficiency. Rather than training separate models for IoT device identification and intrusion detection, MTL employs a shared-encoder architecture to learn representations useful for both tasks. This reduces overfitting, minimises redundant parameters, and improves adaptability to new traffic types. \textcite{Dinh2023} demonstrated that constrained twin variational autoencoders with shared latent spaces significantly improve detection accuracy in low-resource IoT environments. Their findings show that common feature hierarchies, such as packet entropy, byte count, and flow duration, are informative for both anomaly and device classification, indicating that multitask representation learning effectively captures cross-domain correlations.
\\
Furthermore, \textcite{Babar2025} and \textcite{Selvam2025} expanded on this idea through hybrid multitask arc\textcite{Babar2025} and \textcite{Selvam2025} extended this concept with hybrid multitask architectures that combine CNN and RNN modules for simultaneous classification. While these frameworks improved detection precision, they often struggled with task coordination and gradient interference, resulting in unstable convergence. Recent methods, including adaptive loss-weighting and attention-based task balancing, address these challenges by ensuring both primary and auxiliary tasks contribute equally to learning. 
\\
The proposed CNN–Transformer encoder in this study applies proportional loss weighting to balance device identification and intrusion detection, preventing either task from dominating optimisation.g collaboration without direct data sharing. \textcite{Selvam2025} applied a federated CNN–RNN architecture for multi-class intrusion detection, preserving user privacy and reducing the need for centralised data aggregation. Although this approach addresses regulatory and privacy challenges, it introduces new complexities such as communication delays, model divergence due to non-IID (non-independent and identically distributed) data, and limited inter-task learning. Most federated frameworks treat each task independently, thus failing to leverage shared latent representations that could enhance cross-task performance and generalisation.
\\
The current research adopts a single-site multitask configuration rather than a fully federated setting, enabling efficient feature sharing and centralised optimisation while maintaining compliance with privacy-by-design principles. The shared CNN—Transformer encoder captures both temporal–spatial dependencies (through convolutional and attention mechanisms) and inter-task semantics via a unified latent feature space. This joint representation enhances adaptability to new devices and unseen attack categories, as shared features learned from one task can implicitly improve the performance of the other.

\section{Evaluation Practices and Research Gaps}

Modern IoT security research emphasises thorough benchmarking to ensure fair comparisons and practical applicability. 
\textcite{Tseng2024} employed multi-class transformer models on CIC--IoT--2023, setting new standards for accuracy and macro-F1 metrics. 
\textcite{Sajid2024} extended evaluation protocols to include resource utilisation and latency testing, while \textcite{Mahdi2025} examined the robustness of hybrid deep learning under adversarial noise. 
Despite these advances, many studies remain laboratory prototypes with a limited focus on deployability and runtime performance. 
The literature collectively indicates three unresolved deficiencies: 

\begin{enumerate}
    \item Integration gap most studies isolate device identification and intrusion detection, duplicating computation and complicating deployment. 
    \item Operationalisation gap accuracy is prioritised over latency, scalability, and monitoring, limiting real-world adoption. 
    \item Multitask efficiency gap shared learning between related IoT security tasks remains underexplored. 
\end{enumerate}

The proposed research addresses these gaps by unifying device and intrusion tasks in a single CNN Transformer encoder, deploying it as a monitored microservice in a cloud environment, and benchmarking accuracy and latency using the CIC-IoT-IDAD-2024 dataset. 
This alignment of model design, evaluation, and deployment establishes a reproducible pathway for practical IoT intrusion detection in cloud-native systems.
